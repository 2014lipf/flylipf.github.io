<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>此情追忆</title>
  <subtitle>此情可待成追忆</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://flylipf.github.io/"/>
  <updated>2017-08-09T03:39:18.000Z</updated>
  <id>http://flylipf.github.io/</id>
  
  <author>
    <name>lipf</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ZooKeeper选主流程</title>
    <link href="http://flylipf.github.io/2017/08/08/ZooKeeper%E9%80%89%E4%B8%BB%E6%B5%81%E7%A8%8B/"/>
    <id>http://flylipf.github.io/2017/08/08/ZooKeeper选主流程/</id>
    <published>2017-08-08T05:55:20.111Z</published>
    <updated>2017-08-09T03:39:18.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h3><blockquote>
<p><strong>epoch</strong>：逻辑时钟,每条消息都被赋予zxid，zxid全局唯一，zxid有两部分组成：高32位是epoch，低32是epoch内的自增ID，由0开始。每次选出新的Leader，epoch会递增，同时zxid的低32为清0.</p>
<p> <strong>zxid</strong>：zab协议中，消息的编号只能由Leader节点来分配，这样我们可以通过zxid来准确判断事件的先后发生顺序。</p>
</blockquote>
<h3 id="选主流程"><a href="#选主流程" class="headerlink" title="选主流程"></a>选主流程</h3><ul>
<li>服务启动后，候选节点A初始化自身的zxid和epoch；</li>
<li>向其他所有节点发送选主通知；</li>
<li>等待其他节点的回复；</li>
<li>比较节点B的回复信息以及B此时的运行状态，和自身的投票信息。</li>
</ul>
<h4 id="情况1：投票节点是LOOKING状态"><a href="#情况1：投票节点是LOOKING状态" class="headerlink" title="情况1：投票节点是LOOKING状态"></a>情况1：投票节点是LOOKING状态</h4><p>以下以图示法说明此时选主过程：</p>
<p><strong>STEP 1：</strong>处于LOOKING状态的A发起一次选主请求，并将请求广播至B、C节点，而此时B、C也恰好处于LOOKING状态：<br><img src="https://pic3.zhimg.com/v2-db5280d269b09b5a950ce7141dc9ee7a_b.png" alt="enter image description here"><br><strong>STEP 2：</strong>B、C节点处理A的选主消息，其中，B接受A的提议，C拒绝A的提议：<br><img src="https://pic3.zhimg.com/v2-14d24e9fe6f9ff4e90c51a85c702a2d6_b.png" alt="enter image description here"><br>说明：<br>伴随着A的选主消息的一个额外收获是B和C此时都获得了A节点选主的结果（A投票给，记录为<a, a="">），记录该信息，作为后续判断大家是否达成一致的标准。<br><strong>STEP 3：</strong>B将处理结果通知A、C<br><img src="https://pic4.zhimg.com/v2-abb3a37589c2be85b048eae41b0e96ab_b.png" alt="enter image description here"><br>说明：</a,></p>
<ul>
<li>因为B更新了自己的投票，从投票给自己变成投票给A，因此根据协议的定义，需要将该消息扩散出去。而C由于拒绝了A的提议，因此，无需扩散消息；</li>
<li>B将消息扩散给A和C的同时，A和C也就了解了B的投票信息，可以更新本地的投票信息表，例如上面经过B的扩散后，A知道了B节点的投票信息，C知道了A和B节点的投票信息。</li>
</ul>
<p><strong>STEP 4：</strong>C同时也发起选主<br><img src="https://pic2.zhimg.com/v2-c72a3ac6203930e1ee50c8f8c0ae210d_b.png" alt="enter image description here"></p>
<p><strong>STEP 5：</strong>A、B分别处理C的选主请求<br><img src="https://pic4.zhimg.com/v2-328b725c339d8b7be8975ccd3ee1184f_b.png" alt="enter image description here"><br>说明：</p>
<p>这里A和B判断得出C是最合适的Leader，因此A和B都更新自己的候选Leader为C，同时由于C的消息，A和B都更新自身维护的投票信息，增加C的投票信息。</p>
<p><strong>STEP 6：</strong>A、B将更新后的信息扩散到其他节点<br><img src="https://pic2.zhimg.com/v2-8a40dc83e22c95b2ec3e0fea1de1c975_b.png" alt="enter image description here"><br>说明：</p>
<p>因为在第五步中A和B分别将自己的候选Leader变成了C，因此需要将该信息通知到其他节点，其他节点在收到新的投票信息后会更新本地的投票信息列表，如上图。</p>
<p><strong>STEP 7: </strong>选主结束<br>此时此刻，所有的节点都已经达成了一致：每个节点都同意节点C作为新的Leader。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;基础概念&quot;&gt;&lt;a href=&quot;#基础概念&quot; class=&quot;headerlink&quot; title=&quot;基础概念&quot;&gt;&lt;/a&gt;基础概念&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;epoch&lt;/strong&gt;：逻辑时钟,每条消息都被赋予zxid，zxid全局唯一
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>洞悉CPU Cache</title>
    <link href="http://flylipf.github.io/2017/07/31/%E6%B4%9E%E6%82%89CPU%20Cache/"/>
    <id>http://flylipf.github.io/2017/07/31/洞悉CPU Cache/</id>
    <published>2017-07-31T07:59:37.558Z</published>
    <updated>2017-07-31T09:36:36.443Z</updated>
    
    <content type="html"><![CDATA[<h3 id="【CPU-Cache-】"><a href="#【CPU-Cache-】" class="headerlink" title="【CPU Cache 】"></a>【CPU Cache 】</h3><p> <strong>如今的CPU</strong>和几十年前的相比，其运行效率可谓天壤之别。在以前，CPU的工作频率和内存的总线的频率是处于一个量级的，CPU对内存的访问速度也只是比对寄存器的访问要慢一点点。但是近十几年来，CPU的工作频率大大增加，而内存的发展却无法赶上CPU的步伐。当然，当前技术并不是做不出来访问频率高的内存，而是SRAM那样的高速内存相对于普通内存DRAM而言，成本过高。因此，当前系统选择一个折中办法，即在CPU和内存之间引入高速缓存（cache），作为CPU和内存之间的通道。CPU Cache的性能介于寄存器和内存之间，系统常常把经常使用的数据放在Cache中，当对相同数据、内存地址相邻数据多次操作，这样就可以避免到从内存中获取数据，而直接从CPU Cache中获取数据，这样能够提升程序的性能。但是作为高级语言（C、C++、Java等）的开发者而言，有些不懂CPU Cache的人会说：既然我们的CPU Cache性能高，我们只要把我们的数据放在CPU Cache中，那样我们的性能会很高，其实不然。CPU Cache其实完全是透明的，我们是无法干涉它，也是无法察觉它是如何运行的，因为它完全是依赖硬件实现的。但我们可以了解CPU Cache，并合理利用CPU Cache设计自己的程序而给程序性能带来质的提升</p>
<h3 id="【解析CPU架构】"><a href="#【解析CPU架构】" class="headerlink" title="【解析CPU架构】"></a>【解析CPU架构】</h3><p>下面是CPU Cache的简单的示意图：<br><img src="http://rdc.hundsun.com/portal/data/upload/201707/f_aaf1b569eb6b9ec83878e38f4312b8bf.png" alt="Alt text"><br>随着多核的发展，<strong>CPU Cache</strong>分成了三个级别：<code>L1 Cache</code>、 <code>L2 Cache</code>、<code>L3 Cache</code>。级别越低越接近CPU，所以速度也更快， 但是容量也越小。 L1 Cache是最接近CPU的，它容量最小，例如32K，但速度最快，每个核上都有一个L1 Cache（更加确切的来说每个核上有两个L1 Cache，一个存数据 L1d Cache，一个存指令 L1i Cache）。 L2 Cache 更大一些，例如256K，速度要慢一些，一般情况下每个核上都有一个独立的L2 Cache； L3 Cache是三级缓存中最大的一级，例如20MB，同时也是最慢的一级，在同一颗CPU插槽中所有的核共享一个L3 Cache。</p>
<p><strong>Cache Line</strong>可以简单的理解为CPU Cache中的最小缓存单位。目前主流的CPU Cache的Cache Line大小都是64Bytes。即当我们程序需要从内存中读取一个字节的时候，事实上相邻的63字节同时从内存中加载到CPU Cache中，这样当CPU访问相邻的数据的时候，并不会从内存中读取数据，而从CPU Cache中即可访问到数据，这样就提高了速度。</p>
<p>下图是CPU寄存器、缓存、内存的性能指标参考值：<br><img src="http://rdc.hundsun.com/portal/data/upload/201707/f_64028a63a62006782542d356391ff7d0.png" alt="Alt text"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;【CPU-Cache-】&quot;&gt;&lt;a href=&quot;#【CPU-Cache-】&quot; class=&quot;headerlink&quot; title=&quot;【CPU Cache 】&quot;&gt;&lt;/a&gt;【CPU Cache 】&lt;/h3&gt;&lt;p&gt; &lt;strong&gt;如今的CPU&lt;/strong&gt;和几十年前的
    
    </summary>
    
    
  </entry>
  
</feed>
